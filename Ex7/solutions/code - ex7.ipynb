{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true;\n",
       "function code_toggle() {\n",
       "if (code_show){\n",
       "$('div.input').hide();\n",
       "} else {\n",
       "$('div.input').show();\n",
       "}\n",
       "code_show = !code_show\n",
       "}\n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is used for creating a button that hides/unhides code cells to quickly look only the results.\n",
    "# Works only with Jupyter Notebooks.\n",
    "\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n",
      "Data stored in /coursedata/exercise-07-data\n"
     ]
    }
   ],
   "source": [
    "# Description:\n",
    "#   Exercise7 notebook.\n",
    "#\n",
    "# Copyright (C) 2018 Santiago Cortes, Juha Ylioinas\n",
    "#\n",
    "# This software is distributed under the GNU General Public \n",
    "# Licence (version 2 or later); please refer to the file \n",
    "# Licence.txt, included with the software, for details.\n",
    "\n",
    "# Preparations\n",
    "import numpy as np\n",
    "\n",
    "# Select data directory\n",
    "if os.path.isdir('/coursedata'):\n",
    "    # JupyterHub\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../../../coursedata'):\n",
    "    # Local installation\n",
    "    course_data_dir = '../../../coursedata'\n",
    "else:\n",
    "    # Docker\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-07-data')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 7\n",
    "The problems should be solved before the exercise session and solutions returned via\n",
    "MyCourses. <br><br> For this exercise round, upload this notebook(pdf and .ipynb versions) containing your source codes (for Exercise 1) and your answer to the question of Exercise2, and all the answers to the questions of Exercise 3 (VGG practical), see part[1-3].ipynb. Note that it's not necessary to upload part1.ipynb, part2.ipynb or part3.ipynb, because all of the necessary questions related to them are contained in this notebook and you're not expected to do any coding in Exercises 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Comparing  bags-of-words  with  tf-idf  weighting\n",
    "Assume  that  we  have  an  indexed  collection  of  documents  containing  the  five  terms  of the following table where the second row indicates the percentage of documents in which each term appears.<br>\n",
    "\n",
    "| term | cat | dog |mammals | mouse | pet |\n",
    "| --- | :---: | :---: | :---: | :---: | :---: |\n",
    "| **% of documents** | 5 | 20 | 2 | 10 | 60 |\n",
    "\n",
    "Now, given the query $Q=\\{mouse, cat, pet, mammals\\}$, compute the similarity between $Q$ and the following example documents $D1$, $D2$, $D3$, by using the cosine similarity measure and tf-idf weights (i.e. term frequency - inverse document frequency) for the bag-of-words histogram representations of the documents and the query.\n",
    "\n",
    "-  $D1$ = Cat is a pet, dog is a pet, and mouse may be a pet too.\n",
    "-  $D2$ = Cat, dog and mouse are all mammals.\n",
    "-  $D3$ = Cat and dog get along well, but cat may eat a mouse.\n",
    "\n",
    "Ignore other words except the five terms. You may proceed with the following steps:\n",
    "\n",
    "a) Compute and report the inverse document frequency (idf) for each of the five terms. Use the logarithm with base 2. (idf is the logarithm on slide 69 of Lecture 6.)<br>\n",
    "b) Compute the term frequencies for the query and each document. <br>\n",
    "c) Form the tf-idf weighted word occurrence histograms for the query and documents. <br>\n",
    "d) Evaluate the cosine similarity between the query and each document (i.e.\\ normalized scalar product between the weighted occurrence histograms as shown on slide 45).<br> \n",
    "e) Report the relative ranking of the documents. (You should get similarities 0.95, 0.64, and 0.63, but you need to determine which corresponds to which document.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cat', 'pet', 'dog', 'pet', 'mouse', 'pet'],\n",
       " ['cat', 'dog', 'mouse', 'mammals'],\n",
       " ['cat', 'dog', 'cat', 'mouse']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Comparing  bags-of-words  with  tf-idf  weighting\n",
    "##--your-code-starts-here--##\n",
    "\n",
    "# data\n",
    "q = [\"mouse\",\"cat\",\"pet\",\"mammals\"]\n",
    "\n",
    "documents = [\n",
    "    \"Cat is a pet, dog is a pet, and mouse may be a pet too.\",\n",
    "    \"Cat, dog and mouse are all mammals.\",\n",
    "    \"Cat and dog get along well, but cat may eat a mouse.\"\n",
    "]\n",
    "\n",
    "terms = [\"cat\",\"dog\",\"mammals\",\"mouse\",\"pet\"]\n",
    "\n",
    "document_percent = {\"cat\":0.05,\"dog\":0.2,\"mammals\":0.02,\"mouse\":0.1,\"pet\":0.6}\n",
    "\n",
    "# turn documents into bags of words, keeping only given terms\n",
    "d_bags = []\n",
    "for d in documents:\n",
    "    unfiltered_bag = d.lower().replace(',','').replace('.','').split()\n",
    "    filtered_bag = []\n",
    "    for w in unfiltered_bag:\n",
    "        if w in terms:\n",
    "            filtered_bag.append(w)\n",
    "    d_bags.append(filtered_bag)\n",
    "    \n",
    "d_bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 4.321928094887363,\n",
       " 'dog': 2.321928094887362,\n",
       " 'mammals': 5.643856189774724,\n",
       " 'mouse': 3.321928094887362,\n",
       " 'pet': 0.7369655941662062}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) calculate inverse document frequency\n",
    "idf = {t:np.log2(1/n) for (t,n) in document_percent.items()}\n",
    "\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cat': 0.16666666666666666,\n",
       "  'dog': 0.16666666666666666,\n",
       "  'mammals': 0.0,\n",
       "  'mouse': 0.16666666666666666,\n",
       "  'pet': 0.16666666666666666},\n",
       " {'cat': 0.25, 'dog': 0.25, 'mammals': 0.25, 'mouse': 0.25, 'pet': 0.0},\n",
       " {'cat': 0.25, 'dog': 0.25, 'mammals': 0.0, 'mouse': 0.25, 'pet': 0.0},\n",
       " {'cat': 0.25, 'dog': 0.0, 'mammals': 0.25, 'mouse': 0.25, 'pet': 0.25}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) calculate term frequencies\n",
    "d_bags.append(q)\n",
    "\n",
    "tf = []\n",
    "for d in d_bags:\n",
    "    occurrences = {t:0 for t in terms}\n",
    "    for t in terms:\n",
    "        if t in d:\n",
    "            occurrences[t] += 1\n",
    "    term_freqs = {t:n/len(d) for (t,n) in occurrences.items()}\n",
    "    tf.append(term_freqs)\n",
    "    \n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7203213491478937,\n",
       "  0.3869880158145603,\n",
       "  0.0,\n",
       "  0.553654682481227,\n",
       "  0.12282759902770103],\n",
       " [1.0804820237218407,\n",
       "  0.5804820237218405,\n",
       "  1.410964047443681,\n",
       "  0.8304820237218405,\n",
       "  0.0],\n",
       " [1.0804820237218407, 0.5804820237218405, 0.0, 0.8304820237218405, 0.0],\n",
       " [1.0804820237218407,\n",
       "  0.0,\n",
       "  1.410964047443681,\n",
       "  0.8304820237218405,\n",
       "  0.18424139854155155]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c) generate histograms\n",
    "titles = [\"Doc 1\", \"Doc 2\", \"Doc 3\", \"Query\"]\n",
    "tf_idf = [[tf[i][t]*idf[t] for t in terms] for i in range(len(d_bags))]\n",
    "\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6430234838611961, 0.9546948111493487, 0.6363473188622558]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d) cosine similarity between query and documents\n",
    "cos_sim = []\n",
    "for i in range(len(documents)):\n",
    "    num = np.dot(tf_idf[i], tf_idf[-1])\n",
    "    denom = np.linalg.norm(tf_idf[i])*np.linalg.norm(tf_idf[-1])\n",
    "    cos_sim.append(num/denom)\n",
    "\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative ranking of documents is as follows:\n",
      "Number 1 is document 2\n",
      "Number 2 is document 1\n",
      "Number 3 is document 3\n"
     ]
    }
   ],
   "source": [
    "# e) relative ranking\n",
    "sorted_cos_sim = sorted(cos_sim, reverse=True)\n",
    "\n",
    "print(\"Relative ranking of documents is as follows:\")\n",
    "for i, cs in enumerate(sorted_cos_sim):\n",
    "    print(\"Number {} is document {}\".format(i+1, cos_sim.index(cs)+1))\n",
    "    \n",
    "##--your-code-ends-here--##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Precision  and  recall\n",
    "There is a database of 10000 images and a user, who is only interested in images which contain a car. It is known that there are 500 such images in the database. An  automatic image retrieval system retrieves 300 car images and 50 other images from the database. Determine and report the precision and recall of the retrieval  system in this particularcase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here:\n",
    "\n",
    "We have that precision = #relevant/#returned, so in this case \n",
    "\n",
    "**precision = 300/(300+50) = 0.857**\n",
    "\n",
    "We have that recall = #relevant/#total_relevant, so in this case \n",
    "\n",
    "**recall = 300/(500) = 0.6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - VGG practical on object instance recognition\n",
    "See the questions in part[1-3].ipynb and write your answers here.\n",
    "\n",
    "Type your answers here:\n",
    "\n",
    "### Part1:\n",
    "#### Stage I.A \n",
    "* The change in density of detections across the image is a byproduct of the fact that SIFT, while invariant to translation, scaling, and rotation, is not invariant to intensity changes. Since in the real pair of images the two pictures have very different intensity values, with the second image even being partially in sunlight and partially in shadow, SIFT is not able to correctly identify as many frames, which will likely be a problem for matching. Some kind of normalization on the intensity values, or turning the image to greyscale, might help mitigate the problem.\n",
    "* A feature may be detected multiple times with different orientations if the orientation of the edges in it is not clear. This may be the result for example of \"noisy\" areas with no distinct straight lines.\n",
    "\n",
    "#### Stage I.B \n",
    "* The descriptors are computed over a larger region compared to the detection in order to also take into account the larger surrounding region of the frames, thus also considering the \"context\" and improving the matching and differentiation of points in the image.\n",
    "* By observing the pairings of points between the two images we can surmise that the mismatches are indeed influenced by the changes in intensity, as areas appear to be more likely to be associated with other areas of similar intensity regardless of actual similarity. Using more sophisticated matching methods, such as those seen in previous exercise sessions, may yield better results.\n",
    "\n",
    "#### Stage I.C\n",
    "* The remaining mismatches appear to still be regions with intensity values very different from the rest of the image. Lowering the nnThreshold value results in less mismatches but might also risks missing some true positives. Using more advanced algorithms such as RANSAC may be more effective.\n",
    "\n",
    "### Part2:\n",
    "* While the transformations move beyond affine to planar homographies, using the combination of SIFT descriptors and affine adaptation (producing elliptical descriptors that supplement SIFT's ability to match areas of the pictures) still yields much improved results compared to simply using SIFT, and still manages to produce acceptable matching when the transformation is not excessively extreme (with diminishing result as the warping worsens).\n",
    "\n",
    "### Part3:\n",
    "#### Stage III.A\n",
    "* The number of clusters affects the performance of the algorithm because a larger vocabulary will improve matching by ensuring that only the most similar features are grouped under the same cluster, but will also result in longer computations as each image has to be compared with a higher number of items.\n",
    "* The time required to convert descriptors into visual words is not considered as it is low enough to not be significant, and the computation for the most part needs only to be carried out at the beginning.\n",
    "* The computational time is for the most part related only to the number of clusters and their size, the latter of which may vary linearly with database size.\n",
    "\n",
    "#### Stage III.B\n",
    "* 14 images were erroneously matched. The first image likely has a score of ~1 because it is the same image used for the query, and thus it stands to reason that it would have maximum similarity with itself.\n",
    "\n",
    "#### Stage III.C \n",
    "* As the score does not anymore reflect a similarity measure (but instead the number of inliers) it does not have an upper limit of 1.\n",
    "* Since we are merely rescoring the top 25 images the set of matched images is of course the same, but we can see their ordering is now much improved, with the correct matches being displayed first as they posess the highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
